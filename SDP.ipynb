{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><span style=\"font-family: Arial; font-size:2em;color:blue;\"><b> Final project in Compressed Sensing </b></p> \n",
    "</center>\n",
    "\n",
    "&NewLine;\n",
    "\n",
    "\n",
    "<center><span style=\"font-family: Arial; font-size:1.5em;\"><b> Re-implementation for the article \"Semidefinite relaxations for certifying robustness to adversarial examples\"</b></p> \n",
    "</center>\n",
    "\n",
    "\n",
    "&NewLine;\n",
    "\n",
    "<center><span style=\"font-family: Arial; font-size:1em;\"> VU Thi Van Anh \n",
    "    </p> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent advances deep learning and deep neural networks are widely used in solving multiple important practical problems such as image/ speech recognition, text classification and others. However, most existing machine learning classifiers, notably the neural network are highly vulnerable to adversarial problems. In recent years, many works (Szegedy et al., 2013; Goodfellow et al., 2014b; He et al., 2016) have shown that DNN models are vulnerable to adversarial examples, which can be formally defined as – “Adversarial examples are inputs to machine learning models that an attacker intentionally designed to cause the model to make mistakes.” In the image classification domain, these adversarial examples are intentionally synthesized images which look almost exactly the same as the original images, but can mislead the classifier to provide wrong prediction outputs with high confidence.\n",
    "\n",
    "To deal with the threat of adversarial examples, several studied has been conducted such as Gradient Masking (Papernot et al., 2016b; Athalye et al., 2018), Robust\n",
    "Optimization (Madry et al., 2017; Kurakin et al., 2016b) and Adversary Detection (Carlini & Wagner, 2017a; Xu et al., 2017). However, in this paper, we study the **certified defenses against attacks on neural network** proposed by Raghunathan et al, 2018. This paper proposed a Semidefinite Programming (SDP) relaxation for multi-layer networks with Rectified Linear Unit (Relu) activations and adversaries bounded by infinity norm ball. In this paper, the authors express the ReLu constraint as an equivalent quadratic constraint and the method adopted here formulates these as quadratic constraints to obtain a quadratic program that is then relaxed to an SDP. The experimental results are compelling, constructing the first certificate of robustness for verification-oblivious MNIST models with respect to moderate sized $L\\infty$ perturbations.  \n",
    "\n",
    "\n",
    "In this project, we focus on re-implementing SDP methods as propsed paper and testing this method with 3 models Grad-NN, LP-NN and PGD-NN. Our notebook is organized as below:\n",
    "- Introducing\n",
    "- Using different models to run cerfitication\n",
    "  - **Grad-NN**: In this subsection, we'll consider a two-layer network based on an SDP bound on the gradient of the network.\n",
    "  - **LP-NN**: In this subsection, we'll consider a two-layer network based on the Linear Programming training procedure. Linear Programming is a special case of SDP when the constraint is linear. Comparing the SDP which can handles arbitrary number of layers, LP-based neural network only accepts a layer number restricted to twp.\n",
    "  - **PGD-NN**: We consider a fully-connected network with four layers containing 200;100 and 50 hidden nodes (i.e., the architecture is 784-200-100-50-10). We train this network using trainin against the strong PGD attack. \n",
    "  \n",
    "  Furthermore, in each model above, we try to test with created attacks (10000 images) which are constructed by adding noises to original images, a natural idea is to de-noise adversarial examples before sending them to the target model and consider if these models can remove all adversarial perturbations?\n",
    "- Conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prequirement**\n",
    "\n",
    "In this following part of code, different convex program arises in the certification procedure are solve by toolbox **YALMIP** with **MOSEK** as backend in **MATLAB**.\n",
    "\n",
    "Several required packages for MATLAB includes:\n",
    "\n",
    "- YALMIP\n",
    "- SEDUMI\n",
    "- SDPT3\n",
    "- MOSEK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import neural_net_params\n",
    "import read_weights\n",
    "import matlab_interface\n",
    "import compute_bounds\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of X (70000, 784)\n",
      "Dimension of Y (70000,)\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset parameters\n",
    "num_rows = 28\n",
    "num_columns = 28\n",
    "num_channels = 1\n",
    "\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = sio.loadmat('/Users/hoang/THANG HOANG/mnist-original.mat')\n",
    "X, Y = mnist['data'].T, mnist['label'].ravel()\n",
    "\n",
    "# Dimension\n",
    "print('Dimension of X {}'.format(X.shape))\n",
    "print('Dimension of Y {}'.format(Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation of model 1- Grad-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve model and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model1/dense_1/bias', 'model1/dense/bias', 'model1/dense_1/kernel', 'model1/dense/kernel'])\n"
     ]
    }
   ],
   "source": [
    "# Load model from checkpoint\n",
    "reader = tf.train.load_checkpoint(\"models/nips_sdp.ckpt\")\n",
    "\n",
    "# Get variables' names\n",
    "variable_map = reader.get_variable_to_shape_map()\n",
    "checkpoint_variable_names = variable_map.keys()\n",
    "\n",
    "print(checkpoint_variable_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model feedforward NN with no activation function** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This model is only feedforward layer with no activations\n",
    "net_layer_types = ['ff_relu', 'ff']\n",
    "\n",
    "# Get weights  \n",
    "net_weights = [\n",
    "    reader.get_tensor(tensor_str='model1/dense/kernel').T,\n",
    "    reader.get_tensor(tensor_str='model1/dense_1/kernel').T\n",
    "]\n",
    "\n",
    "# Get biases\n",
    "net_biases = [\n",
    "    reader.get_tensor(tensor_str='model1/dense/bias'),\n",
    "    reader.get_tensor(tensor_str='model1/dense_1/bias')\n",
    "]\n",
    "\n",
    "# Re-build neural net\n",
    "nn_params = neural_net_params.NeuralNetParams(\n",
    "  net_weights, net_biases, net_layer_types)\n",
    "\n",
    "# Get an image belonging to class 0 from MNIST to run certification\n",
    "test_input = X[0].reshape(-1,1) / 255.\n",
    "true_class = Y.astype(int)[0]\n",
    "\n",
    "\n",
    "# Check this image\n",
    "plt.figure()\n",
    "plt.imshow(test_input.reshape(28, 28))\n",
    "plt.gray()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some parameters for running certification on adversarial class 1 \n",
    "adv_class = 1\n",
    "matlab_folder = 'matlab_folder'\n",
    "epsilon = 0.1\n",
    "input_minval = 0\n",
    "input_maxval = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SDP Certification on adversarial class 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matlab_folder\n",
      "(500, 784)\n",
      "Input example is robust to perturbation to adv class 1\n",
      "Input example succesfully verified\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    if not os.path.exists(matlab_folder):\n",
    "        os.mkdir(matlab_folder)\n",
    "    matlab_object = matlab_interface.MatlabInterface(matlab_folder)\n",
    "    # Save weights of NN model to matlab_object\n",
    "    matlab_object.save_weights(nn_params, sess)\n",
    "    opt_params = {}\n",
    "    opt_params['test_input'] = test_input\n",
    "    opt_params['epsilon'] = epsilon\n",
    "    opt_params['true_class'] = true_class\n",
    "    opt_params['adv_class'] = adv_class\n",
    "    opt_params['final_linear'] = sess.run(nn_params.final_weights[adv_class, :]\n",
    "             - nn_params.final_weights[true_class, :])\n",
    "    opt_params['final_constant'] = sess.run(nn_params.final_bias[adv_class]\n",
    "               - nn_params.final_bias[true_class])\n",
    "    lower, upper = compute_bounds.compute_bounds(test_input, epsilon,\n",
    "                                       input_minval, input_maxval, nn_params)\n",
    "    opt_params['lower'] = [sess.run(l) for l in lower]\n",
    "    opt_params['upper'] = [sess.run(u) for u in upper]\n",
    "    # Save optimisation's parameters to matlab_object\n",
    "    matlab_object.save_opt_params(opt_params)\n",
    "    \n",
    "    \n",
    "    # Run certification by resolving a optimisation problem on Matlab\n",
    "    os.system('matlab -sd \"THANG HOANG\\SDP\" -batch \"matlab_sdp(\\'matlab_folder\\')\"')\n",
    "    \n",
    "    \n",
    "    # Retrieve results and determine whether this input is certified\n",
    "    opt_val = sio.loadmat(os.path.join(matlab_folder, 'SDP_optimum.mat'))\n",
    "    opt_val = opt_val['val']\n",
    "    if(opt_val < 0):\n",
    "        print('Input example is robust to perturbation to adv class ' + str(adv_class))\n",
    "    else:\n",
    "        print('Input example cannot be certified as robust to perturbation to adv class ' + str(adv_class))\n",
    "        exit()\n",
    "print('Input example succesfully verified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get 10.000 fake images\n",
    "fake_images = np.repeat(test_input, 10000, axis=1) + np.random.uniform(-1, 1, (784, 10000))*0.1\n",
    "\n",
    "# Calculating output\n",
    "out_layer_1 = np.maximum(0, net_weights[0].dot(fake_images) + net_biases[0].reshape(-1, 1))\n",
    "output = net_weights[1].dot(out_layer_1) + net_biases[1].reshape(-1, 1)\n",
    "\n",
    "# Predicted values\n",
    "Y_pred = np.argmax(output, axis = 0)\n",
    "\n",
    "# Check incorrectly predicted values in class 1\n",
    "np.sum(Y_pred == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0], dtype=int64), array([10000], dtype=int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation model 2: LP-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve model and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model1/dense_1/bias', 'model1/dense/bias', 'model1/dense_1/kernel', 'model1/dense/kernel'])\n"
     ]
    }
   ],
   "source": [
    "# Load model from checkpoint\n",
    "reader = tf.train.load_checkpoint(\"models/nips_lp.ckpt\")\n",
    "\n",
    "# Get variables' names\n",
    "variable_map = reader.get_variable_to_shape_map()\n",
    "checkpoint_variable_names = variable_map.keys()\n",
    "\n",
    "print(checkpoint_variable_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model feedforward NN with no activation function** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This model is only feedforward layer with no activations\n",
    "net_layer_types = ['ff', 'ff']\n",
    "\n",
    "# Get weights  \n",
    "net_weights = [\n",
    "    reader.get_tensor(tensor_str='model1/dense/kernel').T,\n",
    "    reader.get_tensor(tensor_str='model1/dense_1/kernel').T\n",
    "]\n",
    "\n",
    "# Get biases\n",
    "net_biases = [\n",
    "    reader.get_tensor(tensor_str='model1/dense/bias'),\n",
    "    reader.get_tensor(tensor_str='model1/dense_1/bias')\n",
    "]\n",
    "\n",
    "# Re-build neural net\n",
    "nn_params = neural_net_params.NeuralNetParams(\n",
    "  net_weights, net_biases, net_layer_types)\n",
    "\n",
    "# Get an image belonging to class 0 from MNIST to run certification\n",
    "test_input = X[0].reshape(-1,1) / 255.\n",
    "true_class = Y.astype(int)[0]\n",
    "\n",
    "# Check this image\n",
    "plt.figure()\n",
    "plt.imshow(test_input.reshape(28, 28))\n",
    "plt.gray()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because true_class = 0, we want to run certification on adversarial class = 6\n",
    "adv_class = 6\n",
    "input_minval = 0\n",
    "input_maxval = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SDP Certification on adversarial class 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matlab_folder\n",
      "(500, 784)\n",
      "Input example is robust to perturbation to adv class 6\n",
      "Input example succesfully verified\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    if not os.path.exists(matlab_folder):\n",
    "        os.mkdir(matlab_folder)\n",
    "    matlab_object = matlab_interface.MatlabInterface(matlab_folder)\n",
    "    # Save weights of NN model to matlab_object\n",
    "    matlab_object.save_weights(nn_params, sess)\n",
    "    opt_params = {}\n",
    "    opt_params['test_input'] = test_input\n",
    "    opt_params['epsilon'] = epsilon\n",
    "    opt_params['true_class'] = true_class\n",
    "    opt_params['adv_class'] = adv_class\n",
    "    opt_params['final_linear'] = sess.run(nn_params.final_weights[adv_class, :]\n",
    "             - nn_params.final_weights[true_class, :])\n",
    "    opt_params['final_constant'] = sess.run(nn_params.final_bias[adv_class]\n",
    "               - nn_params.final_bias[true_class])\n",
    "    lower, upper = compute_bounds.compute_bounds(test_input, epsilon,\n",
    "                                       input_minval, input_maxval, nn_params)\n",
    "    opt_params['lower'] = [sess.run(l) for l in lower]\n",
    "    opt_params['upper'] = [sess.run(u) for u in upper]\n",
    "    # Save optimisation's parameters to matlab_object\n",
    "    matlab_object.save_opt_params(opt_params)\n",
    "    \n",
    "  \n",
    "    # Run certification by resolving a optimisation problem on Matlab\n",
    "    os.system('matlab -sd \"THANG HOANG\\SDP\" -batch \"matlab_sdp(\\'matlab_folder\\')\"')\n",
    "    \n",
    "    \n",
    "    # Retrieve results and determine whether this input is certified\n",
    "    opt_val = sio.loadmat(os.path.join(matlab_folder, 'SDP_optimum.mat'))\n",
    "    opt_val = opt_val['val']\n",
    "    if(opt_val < 0):\n",
    "        print('Input example is robust to perturbation to adv class ' + str(adv_class))\n",
    "    else:\n",
    "        print('Input example cannot be certified as robust to perturbation to adv class ' + str(adv_class))\n",
    "        exit()\n",
    "print('Input example succesfully verified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get 10.000 fake images\n",
    "fake_images = np.repeat(test_input, 10000, axis=1) + np.random.uniform(-1, 1, (784, 10000))*0.1\n",
    "\n",
    "# Calculate predicted values\n",
    "out_layer_1 = net_weights[0].dot(fake_images) + net_biases[0].reshape(-1, 1)\n",
    "output = net_weights[1].dot(out_layer_1) + net_biases[1].reshape(-1, 1)\n",
    "\n",
    "Y_pred = np.argmax(output, axis = 0)\n",
    "\n",
    "# Incorrectly predicted values \n",
    "np.sum(Y_pred == adv_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0], dtype=int64), array([10000], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted values and its occurrence\n",
    "np.unique(Y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying on model 3: PGD-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve model and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model1/dense_1/bias', 'model1/dense/bias', 'model1/dense_1/kernel', 'model1/dense/kernel', 'model1/dense_2/bias', 'model1/dense_2/kernel', 'model1/dense_3/kernel', 'model1/dense_3/bias'])\n"
     ]
    }
   ],
   "source": [
    "reader = tf.train.load_checkpoint(\"models/nips_pgd.ckpt\")\n",
    "\n",
    "# Get variables' names\n",
    "variable_map = reader.get_variable_to_shape_map()\n",
    "checkpoint_variable_names = variable_map.keys()\n",
    "\n",
    "print(checkpoint_variable_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model is only feedforward layer with ReLU activations\n",
    "net_layer_types = ['ff_relu', 'ff_relu', 'ff_relu', 'ff']\n",
    "\n",
    "# Get weights  \n",
    "net_weights = [\n",
    "    reader.get_tensor(tensor_str='model1/dense/kernel').T,\n",
    "    reader.get_tensor(tensor_str='model1/dense_1/kernel').T,\n",
    "    reader.get_tensor(tensor_str='model1/dense_2/kernel').T,\n",
    "    reader.get_tensor(tensor_str='model1/dense_3/kernel').T,\n",
    "]\n",
    "\n",
    "# Get biases\n",
    "net_biases = [\n",
    "    reader.get_tensor(tensor_str='model1/dense/bias'),\n",
    "    reader.get_tensor(tensor_str='model1/dense_1/bias'),\n",
    "    reader.get_tensor(tensor_str='model1/dense_2/bias'),\n",
    "    reader.get_tensor(tensor_str='model1/dense_3/bias'),\n",
    "]\n",
    "\n",
    "# Re-build neural net\n",
    "nn_params = neural_net_params.NeuralNetParams(\n",
    "  net_weights, net_biases, net_layer_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Get randomly an image from MNIST to run certification\n",
    "ind = np.random.randint(len(X))\n",
    "\n",
    "test_input = X[ind].reshape(-1,1) / 255.\n",
    "true_class = Y.astype(int)[ind]\n",
    "print(true_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAABg5JREFUeJzt3T+oT38cx/F7bgYUCwZSBpnuJsIk5SabP93FIFcp892UiTKYrrKYFHV1y6CU4Q6sFmWh2ERSGAhF6fym3/S73/f35/t1v/d+z+vxGL07f7r1vJ/yueecpm3bCaD7Jlf7BoDREDuEEDuEEDuEEDuEWDfKizVN47/+YYW1bdss9+9Wdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdggx0ldJszImJ3v/zj506FB57OXLl8v5sWPHynnTLPvW4v91/NLSUnksf5eVHUKIHUKIHUKIHUKIHUKIHUKIHULYZ++AS5cu9ZxduXJlqHP32wv/+fNnOZ+amhr43PxdVnYIIXYIIXYIIXYIIXYIIXYIIXYI0bRtO7qLNc3oLtYh1fPqExMTE2/evOk527FjR3nsy5cvy3m/5+G/fftWzhm9tm2XfcmAlR1CiB1CiB1CiB1CiB1CiB1CiB1CeJ59DMzPz5fzai/97du35bHT09Pl3D56d1jZIYTYIYTYIYTYIYTYIYTYIYSttzFQvY65n8+fP5fzDx8+DHxuxouVHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUJ4nr3jPn78uNq3wBphZYcQYocQYocQYocQYocQYocQYocQ9tk7bnFxcbVvgTXCyg4hxA4hxA4hxA4hxA4hxA4hxA4h7LN33Pnz58v57du3R3QnrDYrO4QQO4QQO4QQO4QQO4QQO4Sw9dZxGzduXNHz7969u5xv3bq15+zChQvlsU+ePCnnDx48KOffv38v52ms7BBC7BBC7BBC7BBC7BBC7BBC7BDCPjul69evl/Nz586V8y1btgx87dnZ2XL+4sWLcn727Nmes+fPnw90T+PMyg4hxA4hxA4hxA4hxA4hxA4hxA4h7LN33Pbt28v5vXv3yvnMzEw5b5rmj+/pX58+fSrnmzZtKudTU1PlfGlpqefs+PHj5bHPnj0r5+PIyg4hxA4hxA4hxA4hxA4hxA4hxA4hmrZtR3exphndxTrk7t275fzMmTMrdu3fv3+X86tXr5bzV69e9Zz1e+/73r17y/nCwkI537VrV89Zv3fSHz16tJyvZW3bLvvHD1Z2CCF2CCF2CCF2CCF2CCF2CCF2COF59jEwPz9fzk+cONFzNuz32efm5sr5zZs3hzp/5enTp+X81q1b5fzatWt/83bGnpUdQogdQogdQogdQogdQogdQth6GwM7d+4s5xs2bFixay8uLq7YuYd16tSp1b6FsWJlhxBihxBihxBihxBihxBihxBihxD22cfA5GT9O3mYzyb3c/DgwXL+8OHDFbv29PR0Od+zZ8/A53737t3Ax44rKzuEEDuEEDuEEDuEEDuEEDuEEDuE8MnmMbB58+Zy/vr1656zbdu2DXXtHz9+lPN9+/aV8+qTzYcPHy6P7fdJ534/l8ePH/ecnT59ujz269ev5Xwt88lmCCd2CCF2CCF2CCF2CCF2CCF2CGGfvQMOHDjQc3bjxo3y2P379w917UePHpXz6m8ALl68WB67fv36cv7+/ftyPjMz03PW73PQ48w+O4QTO4QQO4QQO4QQO4QQO4Sw9dZxJ0+eLOf3798f0Z38169fv8r5wsJCOZ+bmyvnX758+eN76gJbbxBO7BBC7BBC7BBC7BBC7BBC7BDCPnvH9XtM9MiRI+W83z58v/NXZmdny/mdO3cGPncy++wQTuwQQuwQQuwQQuwQQuwQQuwQwj47dIx9dggndgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgjRtG272vcAjICVHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUL8A76b5qtjw5XHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check this image\n",
    "plt.figure()\n",
    "plt.imshow(test_input.reshape(28, 28))\n",
    "plt.gray()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because true_class = 6, we want to run certification on adversarial class = 5\n",
    "adv_class = 5\n",
    "input_minval = 0\n",
    "input_maxval = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SDP Certification on adversarial class 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matlab_folder\n",
      "(200, 784)\n",
      "(100, 200)\n",
      "(50, 100)\n",
      "Input example is robust to perturbation to adv class 5\n",
      "Input example succesfully verified\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    if not os.path.exists(matlab_folder):\n",
    "        os.mkdir(matlab_folder)\n",
    "    matlab_object = matlab_interface.MatlabInterface(matlab_folder)\n",
    "    # Save weights of NN model to matlab_object\n",
    "    matlab_object.save_weights(nn_params, sess)\n",
    "    opt_params = {}\n",
    "    opt_params['test_input'] = test_input\n",
    "    opt_params['epsilon'] = epsilon\n",
    "    opt_params['true_class'] = true_class\n",
    "    opt_params['adv_class'] = adv_class\n",
    "    opt_params['final_linear'] = sess.run(nn_params.final_weights[adv_class, :]\n",
    "             - nn_params.final_weights[true_class, :])\n",
    "    opt_params['final_constant'] = sess.run(nn_params.final_bias[adv_class]\n",
    "               - nn_params.final_bias[true_class])\n",
    "    lower, upper = compute_bounds.compute_bounds(test_input, epsilon,\n",
    "                                       input_minval, input_maxval, nn_params)\n",
    "    opt_params['lower'] = [sess.run(l) for l in lower]\n",
    "    opt_params['upper'] = [sess.run(u) for u in upper]\n",
    "    # Save optimisation's parameters to matlab_object\n",
    "    matlab_object.save_opt_params(opt_params)\n",
    "    # Run certification by resolving a optimisation problem on Matlab\n",
    "    os.system('matlab -sd \"THANG HOANG\\SDP\" -batch \"matlab_sdp(\\'matlab_folder\\')\"')\n",
    "    # Retrieve results and determine whether this input is certified\n",
    "    opt_val = sio.loadmat(os.path.join(matlab_folder, 'SDP_optimum.mat'))\n",
    "    opt_val = opt_val['val']\n",
    "    if(opt_val < 0):\n",
    "        print('Input example is robust to perturbation to adv class ' + str(adv_class))\n",
    "    else:\n",
    "        print('Input example cannot be certified as robust to perturbation to adv class ' + str(adv_class))\n",
    "        exit()\n",
    "print('Input example succesfully verified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check several attack images can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 10.000 fake images\n",
    "fake_images = np.repeat(test_input, 10000, axis=1) + np.random.uniform(-1, 1, (784, 10000))*0.1\n",
    "\n",
    "# Calculate output\n",
    "out_layer_1 = np.maximum(0, net_weights[0].dot(fake_images) + net_biases[0].reshape(-1, 1))\n",
    "out_layer_2 = np.maximum(0, net_weights[1].dot(out_layer_1) + net_biases[1].reshape(-1, 1))\n",
    "out_layer_3 = np.maximum(0, net_weights[2].dot(out_layer_2) + net_biases[2].reshape(-1, 1))\n",
    "output = net_weights[3].dot(out_layer_3) + net_biases[3].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted values\n",
    "Y_pred = np.argmax(output, axis = 0)\n",
    "np.sum(Y_pred == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6], dtype=int64), array([10000], dtype=int64))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted values and occurrence\n",
    "np.unique(Y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With in the scope of this project, we have re-implemented the certification robustness following methods proposed by the article. More detail, all three networks proposed by the authors were employed for testing the certification with 3 image inputs, which are selected randomly from MNIST.\n",
    "\n",
    "The results show that all these images are certified as robustness to several adversarial examples. Since all of them are certified, we still would like to try other attacks to these models by other adversarial examples (we created 10000 images by adding noise to 3 original images mentioned above) and the results show that there are no fake images can make the model turning incorrect prediction. Thus, it can be seen that this method works for all images we had chosen.\n",
    "\n",
    "\n",
    "However, due to our limit of resources' capacity, we could not do more tests on more different examples with diverse classes. (In the paper, it mentioned that on a 4-core CPU, the average SDP computation took around 25 minutes and the LP around 5 minutes per example. However, it took actually more than 3 hours for each computation.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "THANGHOANG",
   "language": "python",
   "name": "thanghoang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "229.697px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}